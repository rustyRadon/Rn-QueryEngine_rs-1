Performance Goals: Minimize "pointer chasing" (indirection) and eliminate heap allocations during the execution phase.

Foundation,"Query engine basics, Apache Arrow, Type Systems, Data Sources."
Representation,"Logical Plans, DataFrame API, SQL Support."
Execution,"Physical Plans, Query Planning, Joins, Subqueries."
Optimization,"Query Optimizer rules, Execution performance."
Scaling,"Parallel Execution (Cores), Distributed Execution (Clusters)."
Quality,"Testing strategies (Fuzzing), Benchmarking."

...KEY
Term,Simple Explanation
Memory Allocation,"Asking the computer for a ""desk"" to put your data on. Too much ""asking"" makes the engine slow."
The Stack,"A small, incredibly fast ""workbench"" for immediate tasks."
The Heap,"A giant ""warehouse"" for storing large amounts of data (like your columns)."
SIMD,"""Single Instruction, Multiple Data."" A way to tell the CPU ""Add these 8 pairs of numbers at the exact same time"" instead of one by one."

Module	            Description
datatypes	    Type system built on Apache Arrow
datasource	    Data source abstractions and CSV/Parquet readers
logical-plan	Logical plans and expressions
physical-plan	Physical plans and expression evaluation
query-planner	Translation from logical to physical plans
optimizer	    Query optimization rules
sql	            SQL tokenizer, parser, and planner
execution	Q   uery execution engine
examples	    Example queries and benchmarks
benchmarks	    Benchmarking utilities and query benchmarks.

                                    ANATOMY OF THE QUERY ENGINE
use std::sync::Arc;

/// 1. DATA TYPES (The Foundation)
/// Using an enum for the Type System allows for static dispatch during execution.
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum DataType {
    UInt32,
    Float64,
    Utf8,
}

/// 2. LOGICAL PLAN (The "What")
/// A recursive tree structure representing the user's intent.
/// We use Arc (Atomic Reference Count) because plans are often shared across threads.
#[derive(Debug)]
pub enum LogicalPlan {
    /// Scanning a data source like a CSV or Parquet file
    Scan { path: String, schema: Vec<(String, DataType)> },
    /// Filtering rows based on a condition
    Filter { input: Arc<LogicalPlan>, expression: String },
    /// Selecting specific columns
    Projection { input: Arc<LogicalPlan>, columns: Vec<String> },
}

/// 3. PHYSICAL PLAN (The "How")
/// This trait defines the contract for executable code.
/// It is 'Sync' because it must be safe to share across CPU cores.
/// Send + Sync, meaning it can be moved between threads safely.
pub trait PhysicalOperator: Send + Sync + std::fmt::Debug {
    /// Executes the operator and produces a stream of data.
    /// In a real engine, this returns a Stream of RecordBatches.
    fn execute(&self) -> Result<(), EngineError>;
}

#[derive(Debug)]
pub enum EngineError {
    IoError(String),
    Internal(String),
}

/// 4. THE QUERY ENGINE (The Orchestrator)
pub struct QueryEngine {
    // We avoid 'mut' here because the engine configuration should be immutable
    // once initialized, ensuring thread safety without locks.
    version: &'static str,
}

impl QueryEngine {
    pub fn new() -> Self {
        Self { version: "0.1.0" }
    }

    /// The "Planning" stage: Translating 'What' to 'How'
    /// We borrow the LogicalPlan to avoid expensive clones of the plan tree.
    pub fn create_physical_plan(
        &self, 
        logical_plan: &LogicalPlan
    ) -> Arc<dyn PhysicalOperator> {
        // In a real engine, this involves a 'match' statement walking the tree.
        // We return an Arc<dyn Trait> to allow for a heterogenous tree of operators.
        match logical_plan {
            LogicalPlan::Scan { .. } => Arc::new(EmptyExec),
            _ => todo!("Implement other operators"),
        }
    }
}

#[derive(Debug)]
struct EmptyExec;
impl PhysicalOperator for EmptyExec {
    fn execute(&self) -> Result<(), EngineError> {
        Ok(())
    }
} 

// IDIOMATIC TRANSFORMATION:
        // 1. Check if empty
        // 2. If NOT empty, wrap in Int32Column and put in Some()
        // 3. Otherwise, return None
        // 4. Wrap the whole thing in Ok()
        Ok((!batch_data.is_empty()).then_some(Int32Column { data: batch_data }))


////////////////---------------/////////////////
            NOTE ONTHE THREE
////////////////---------------/////////////////

// ============================================================================
// PROJECT: Minimalist Vectorized Query Engine
// ROLE: Principal Rust Systems Engineer (Notes & Implementation)
// ============================================================================

use std::fs::File;
use std::io::{BufReader, Read};
use std::sync::{Arc, Mutex};

/// --- 1. DATA MODEL (The Foundation) ---
/// We use Columnar storage. Instead of a list of "Row" objects, 
/// we have a list of "Columns". This is significantly faster because the 
/// CPU can process contiguous blocks of numbers in its cache.

#[derive(Debug, Clone)]
pub enum Column {
    /// Arc (Atomic Reference Count) allows us to share this column 
    /// across multiple threads without copying the data.
    Int32(Arc<Vec<i32>>),
    Float64(Arc<Vec<f64>>),
}

#[derive(Debug, Clone)]
pub struct RecordBatch {
    /// A Batch is a vertical slice of a table.
    pub columns: Vec<Column>,
    pub names: Vec<String>,
}

/// --- 2. EXECUTION FRAMEWORK (The Job Description) ---
/// This Trait defines how any operator (Scan, Filter, Project) must behave.
pub trait ExecutionTask: Send + Sync {
    /// Pull-based model: Every time we call next_batch, we get a chunk of data.
    /// Returns:
    /// - Ok(Some(Batch)): We found data!
    /// - Ok(None): We reached the end of the data stream.
    /// - Err(String): Something went wrong (e.g., disk failure).
    fn next_batch(&self) -> Result<Option<RecordBatch>, String>;
}

/// --- 3. OPERATOR 1: SCAN (The Loader) ---
/// Responsibility: Read raw binary data from disk into memory.
pub struct ScanWorker {
    pub file_handle: Mutex<BufReader<File>>,
    pub column_name: String,
}

impl ExecutionTask for ScanWorker {
    fn next_batch(&self) -> Result<Option<RecordBatch>, String> {
        let mut guard = self.file_handle.lock().map_err(|_| "Lock poisoned")?;
        let mut buffer = [0u8; 4]; // 4 bytes for an i32
        let mut batch_data = Vec::with_capacity(1024); // Pre-allocate to avoid resizing

        for _ in 0..1024 {
            if guard.read_exact(&mut buffer).is_ok() {
                batch_data.push(i32::from_le_bytes(buffer));
            } else {
                break; // End of file
            }
        }

        // Idiomatic Rust: Convert the bool of "is not empty" into an Option
        Ok((!batch_data.is_empty()).then_some(RecordBatch {
            columns: vec![Column::Int32(Arc::new(batch_data))],
            names: vec![self.column_name.clone()],
        }))
    }
}

/// --- 4. OPERATOR 2: FILTER (The Gatekeeper) ---
/// Responsibility: Drop rows that do not meet a certain requirement.
pub struct FilterWorker {
    pub input: Arc<dyn ExecutionTask>,
    pub predicate: fn(i32) -> bool,
}

impl ExecutionTask for FilterWorker {
    fn next_batch(&self) -> Result<Option<RecordBatch>, String> {
        let input_batch = self.input.next_batch()?;

        // Map over the option: if it's Some, filter the data. If None, return None.
        Ok(input_batch.and_then(|batch| {
            // Hot Path: For simplicity, we assume we are filtering the first column.
            if let Column::Int32(ref data) = batch.columns[0] {
                let filtered: Vec<i32> = data
                    .iter()
                    .filter(|&&val| (self.predicate)(val))
                    .cloned()
                    .collect();

                (!filtered.is_empty()).then_some(RecordBatch {
                    columns: vec![Column::Int32(Arc::new(filtered))],
                    names: batch.names,
                })
            } else {
                None
            }
        }))
    }
}

/// --- 5. OPERATOR 3: PROJECTION (The Slicer) ---
/// Responsibility: Vertical slicing. Only pass through the columns requested.
pub struct ProjectionWorker {
    pub input: Arc<dyn ExecutionTask>,
    pub projection_indices: Vec<usize>,
}

impl ExecutionTask for ProjectionWorker {
    fn next_batch(&self) -> Result<Option<RecordBatch>, String> {
        let input_batch = self.input.next_batch()?;

        Ok(input_batch.map(|batch| {
            let mut projected_cols = Vec::new();
            let mut projected_names = Vec::new();

            for &i in &self.projection_indices {
                // CLONE JUSTIFICATION: Cloning an Arc only increments a counter.
                // It does NOT copy the millions of integers in the column.
                projected_cols.push(batch.columns[i].clone());
                projected_names.push(batch.names[i].clone());
            }

            RecordBatch {
                columns: projected_cols,
                names: projected_names,
            }
        }))
    }
}

/// --- SUMMARY OF PRINCIPAL CONCEPTS ---
/// 
/// 1. Arc<T>: Atomic Reference Counting. Essential for sharing data between 
///    different CPU cores without copying.
/// 2. Zero-Copy: Notice ProjectionWorker doesn't copy data; it just copies 
///    pointers (Arcs) to the data.
/// 3. Vectorization: We process 1024 rows at a time. This amortizes the cost 
///    of function calls and improves CPU performance.
/// 4. Mutex: Used in the ScanWorker to ensure that only one thread moves 
///    the file cursor at a time, preventing data corruption.
/// 5. Error Handling: No .unwrap(). We use Result and the ? operator to 
///    ensure the engine fails gracefully if a file is missing.

fn main() {
    println!("Query Engine Logic Compiled Successfully.");
    // To run this, you would chain these workers:
    // let scan = Arc::new(ScanWorker { ... });
    // let filter = Arc::new(FilterWorker { input: scan, ... });
    // let project = Arc::new(ProjectionWorker { input: filter, ... });
}