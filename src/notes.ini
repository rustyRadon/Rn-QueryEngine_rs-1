Performance Goals: Minimize "pointer chasing" (indirection) and eliminate heap allocations during the execution phase.

Foundation,"Query engine basics, Apache Arrow, Type Systems, Data Sources."
Representation,"Logical Plans, DataFrame API, SQL Support."
Execution,"Physical Plans, Query Planning, Joins, Subqueries."
Optimization,"Query Optimizer rules, Execution performance."
Scaling,"Parallel Execution (Cores), Distributed Execution (Clusters)."
Quality,"Testing strategies (Fuzzing), Benchmarking."

...KEY
Term,Simple Explanation
Memory Allocation,"Asking the computer for a ""desk"" to put your data on. Too much ""asking"" makes the engine slow."
The Stack,"A small, incredibly fast ""workbench"" for immediate tasks."
The Heap,"A giant ""warehouse"" for storing large amounts of data (like your columns)."
SIMD,"""Single Instruction, Multiple Data."" A way to tell the CPU ""Add these 8 pairs of numbers at the exact same time"" instead of one by one."

Module	            Description
datatypes	    Type system built on Apache Arrow
datasource	    Data source abstractions and CSV/Parquet readers
logical-plan	Logical plans and expressions
physical-plan	Physical plans and expression evaluation
query-planner	Translation from logical to physical plans
optimizer	    Query optimization rules
sql	            SQL tokenizer, parser, and planner
execution	Q   uery execution engine
examples	    Example queries and benchmarks
benchmarks	    Benchmarking utilities and query benchmarks.

                                    ANATOMY OF THE QUERY ENGINE
use std::sync::Arc;

/// 1. DATA TYPES (The Foundation)
/// Using an enum for the Type System allows for static dispatch during execution.
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum DataType {
    UInt32,
    Float64,
    Utf8,
}

/// 2. LOGICAL PLAN (The "What")
/// A recursive tree structure representing the user's intent.
/// We use Arc (Atomic Reference Count) because plans are often shared across threads.
#[derive(Debug)]
pub enum LogicalPlan {
    /// Scanning a data source like a CSV or Parquet file
    Scan { path: String, schema: Vec<(String, DataType)> },
    /// Filtering rows based on a condition
    Filter { input: Arc<LogicalPlan>, expression: String },
    /// Selecting specific columns
    Projection { input: Arc<LogicalPlan>, columns: Vec<String> },
}

/// 3. PHYSICAL PLAN (The "How")
/// This trait defines the contract for executable code.
/// It is 'Sync' because it must be safe to share across CPU cores.
/// Send + Sync, meaning it can be moved between threads safely.
pub trait PhysicalOperator: Send + Sync + std::fmt::Debug {
    /// Executes the operator and produces a stream of data.
    /// In a real engine, this returns a Stream of RecordBatches.
    fn execute(&self) -> Result<(), EngineError>;
}

#[derive(Debug)]
pub enum EngineError {
    IoError(String),
    Internal(String),
}

/// 4. THE QUERY ENGINE (The Orchestrator)
pub struct QueryEngine {
    // We avoid 'mut' here because the engine configuration should be immutable
    // once initialized, ensuring thread safety without locks.
    version: &'static str,
}

impl QueryEngine {
    pub fn new() -> Self {
        Self { version: "0.1.0" }
    }

    /// The "Planning" stage: Translating 'What' to 'How'
    /// We borrow the LogicalPlan to avoid expensive clones of the plan tree.
    pub fn create_physical_plan(
        &self, 
        logical_plan: &LogicalPlan
    ) -> Arc<dyn PhysicalOperator> {
        // In a real engine, this involves a 'match' statement walking the tree.
        // We return an Arc<dyn Trait> to allow for a heterogenous tree of operators.
        match logical_plan {
            LogicalPlan::Scan { .. } => Arc::new(EmptyExec),
            _ => todo!("Implement other operators"),
        }
    }
}

#[derive(Debug)]
struct EmptyExec;
impl PhysicalOperator for EmptyExec {
    fn execute(&self) -> Result<(), EngineError> {
        Ok(())
    }
} 

// IDIOMATIC TRANSFORMATION:
        // 1. Check if empty
        // 2. If NOT empty, wrap in Int32Column and put in Some()
        // 3. Otherwise, return None
        // 4. Wrap the whole thing in Ok()
        Ok((!batch_data.is_empty()).then_some(Int32Column { data: batch_data }))


////////////////---------------/////////////////
            NOTE ONTHE THREE
////////////////---------------/////////////////

// ============================================================================
// PROJECT: Minimalist Vectorized Query Engine (V3 - Production Style)
// ROLE: Principal Rust Systems Engineer
// ============================================================================

use std::fs::File;
use std::io::{BufReader, Read};
use std::sync::{Arc, Mutex};
// EXTERNAL CRATE: byteorder is the standard for binary decoding.
use byteorder::{LittleEndian, ReadBytesExt};

/// Represents the physical data types supported by our engine's memory model.
/// We use `Arc<Vec<T>>` to ensure that column data is stored once on the heap
/// and shared via reference counting.
#[derive(Debug, Clone)]
pub enum Column {
    /// 32-bit Signed Integer column
    Int32(Arc<Vec<i32>>),
    /// 64-bit Floating Point column
    Float64(Arc<Vec<f64>>),
}

/// A horizontal slice of a table. In high-performance engines, data is processed
/// in "batches" (usually 1024-4096 rows) to balance CPU cache usage and overhead.
#[derive(Debug, Clone)]
pub struct RecordBatch {
    /// Contiguous memory blocks for each column
    pub columns: Vec<Column>,
    /// Metadata: The names of the columns (e.g., "age", "salary")
    pub names: Vec<String>,
}

/// The core trait for all physical operators. 
/// Every node in the query plan must implement this to produce data.
pub trait ExecutionTask: Send + Sync {
    /// Retrieves the next chunk of data from the stream.
    /// Returns `Ok(None)` to signal "End of Stream" (EOS).
    fn next_batch(&self) -> Result<Option<RecordBatch>, String>;
}

// ----------------------------------------------------------------------------
// OPERATOR: SCAN
// ----------------------------------------------------------------------------

/// Reads raw binary data from a file and transforms it into a `RecordBatch`.
pub struct ScanWorker {
    /// Mutex is required because `BufReader`'s internal cursor changes on every read.
    /// In a multi-threaded context, we must synchronize this "seek" operation.
    pub file_handle: Mutex<BufReader<File>>,
    pub column_name: String,
}

/// --- OPERATOR: SCAN ---
pub struct ScanWorker {
    pub file_handle: Mutex<BufReader<File>>,
    pub column_name: String,
}

impl ExecutionTask for ScanWorker {
    fn next_batch(&self) -> Result<Option<RecordBatch>, String> {
        // 1. LOCKING: Lock the file to prevent race conditions on the file cursor.
        let mut guard = self.file_handle.lock()
            .map_err(|_| "Lock poisoned".to_string())?;

        // 2. PRE-ALLOCATION: Justify capacity of 1024 to minimize heap 'growth' events.
        let mut batch_data = Vec::with_capacity(1024);

        // 3. READ LOOP: Leveraging byteorder for precise numeric extraction.
        for _ in 0..1024 {
            match guard.read_i32::<LittleEndian>() {
                // Success: Value is pushed to the heap-allocated vector.
                Ok(value) => batch_data.push(value),

                // Clean Termination: We hit the end of the file perfectly.
                Err(e) if e.kind() == ErrorKind::UnexpectedEof => break,

                // System Failure: IO error (e.g. disk failure) must be reported, not ignored.
                Err(e) => return Err(e.to_string()),
            }
        }

        // 4. PIPELINE RETURN: Use functional check to avoid empty batch propagation.
        Ok((!batch_data.is_empty()).then_some(RecordBatch {
            columns: vec![Column::Int32(Arc::new(batch_data))],
            names: vec![self.column_name.clone()],
        }))
    }
}

// ----------------------------------------------------------------------------
// OPERATOR: FILTER
// ----------------------------------------------------------------------------

/// Filters rows based on a boolean predicate.
pub struct FilterWorker {
    /// The upstream operator (could be a Scan, another Filter, etc.)
    pub input: Arc<dyn ExecutionTask>,
    /// A pointer to the logic used to evaluate each row.
    pub predicate: fn(i32) -> bool,
}

impl ExecutionTask for FilterWorker {
    fn next_batch(&self) -> Result<Option<RecordBatch>, String> {
        // RECURSIVE PULL: Ask the upstream worker for data.
        let input_batch = self.input.next_batch()?;

        // FUNCTIONAL PIPELINE: Transform the Option without 'if let' branching.
        Ok(input_batch.and_then(|batch| {
            // TYPE SAFETY: We match on the column type.
            match &batch.columns[0] {
                Column::Int32(data) => {
                    // ITERATOR PATTERN: Highly optimized by LLVM; often auto-vectorized.
                    let filtered: Vec<i32> = data.iter()
                        .filter(|&&v| (self.predicate)(v))
                        .copied() // copied() is a zero-cost way to handle i32
                        .collect();

                    // CONDITIONAL RETURN: If no rows pass, this batch effectively disappears.
                    (!filtered.is_empty()).then_some(RecordBatch {
                        columns: vec![Column::Int32(Arc::new(filtered))],
                        names: batch.names,
                    })
                },
                // If the column type doesn't match our predicate, we return None.
                _ => None, 
            }
        }))
    }
}

// ----------------------------------------------------------------------------
// OPERATOR: PROJECTION
// ----------------------------------------------------------------------------

/// Selects a subset of columns from the input batch.
pub struct ProjectionWorker {
    pub input: Arc<dyn ExecutionTask>,
    /// Indices of the columns to retain (e.g., [0, 2] to keep 1st and 3rd columns).
    pub projection_indices: Vec<usize>,
}

impl ExecutionTask for ProjectionWorker {
    fn next_batch(&self) -> Result<Option<RecordBatch>, String> {
        // MAP PATTERN: If upstream gives data, slice it. Otherwise, propagate None.
        Ok(self.input.next_batch()?.map(|batch| {
            // UNZIP PATTERN: Efficiently builds two vectors in a single pass.
            let (cols, names): (Vec<_>, Vec<_>) = self.projection_indices.iter()
                .map(|&i| (batch.columns[i].clone(), batch.names[i].clone()))
                .unzip();

            RecordBatch { columns: cols, names }
        }))
    }
}

////////////////---------------/////////////////
            NOTE ON THE THRE END
////////////////---------------/////////////////

Row ID,Name (String),Age (Int32),Salary (Int32)
1    ,Alice,        15,             0
2    ,Bob           20,            500
3    ,Charlie,      25,            2000
4    ,David,        30,            3500
5    ,Eve,          35,            5000
6    ,Frank         40,            7000